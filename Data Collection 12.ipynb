{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2024-12-12T05:04:48.028833Z",
     "start_time": "2024-12-12T05:04:48.017289Z"
    }
   },
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "881ff08627f9526e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T05:04:49.297039Z",
     "start_time": "2024-12-12T05:04:48.075619Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pyngrok import ngrok\n",
    "import re\n",
    "import subprocess\n",
    "from uuid import uuid4\n",
    "\n",
    "from netunicorn.base import Pipeline\n",
    "# from netunicorn.library.tasks.capture.tcpdump import StartCapture, StopNamedCapture\n",
    "# from netunicorn.library.tasks.measurements.ookla_speedtest import SpeedTest, SpeedTestLinuxImplementation\n",
    "\n",
    "from execute_pipeline import execute_pipeline, healthcheck\n",
    "from get_proxies import get_proxies\n",
    "# from background_traffic import StartBackgroundTraffic, StopNamedBackgroundTraffic\n",
    "from youtube_watcher import WatchYouTubeVideo\n",
    "from vimeo_watcher import WatchVimeoVideo\n",
    "from twitch_watcher import WatchTwitchStream\n",
    "from webdav import UploadToWebDav"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "ea5e082301618841",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T05:04:49.631831Z",
     "start_time": "2024-12-12T05:04:49.365759Z"
    }
   },
   "source": [
    "healthcheck()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Health Check: True\n",
      "[[snl-server-5], <Uncountable node pool with next node template: [aws-fargate-A-cs190n4-, aws-fargate-B-cs190n4-, aws-fargate-ARM64-cs190n4-]>]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "fa6cc8b3fc7cb925",
   "metadata": {},
   "source": [
    "Manually `exec` each module so they get pickled by value."
   ]
  },
  {
   "cell_type": "code",
   "id": "ac528d2c57dd861a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T05:04:49.640195Z",
     "start_time": "2024-12-12T05:04:49.637416Z"
    }
   },
   "source": [
    "# __name_bak__ = __name__\n",
    "# for __name__ in [\n",
    "#     \"background_traffic\",\n",
    "#     \"youtube_watcher\",\n",
    "#     \"vimeo_watcher\",\n",
    "#     \"twitch_watcher\",\n",
    "#     \"webdav\"\n",
    "# ]:\n",
    "#     with open(f\"{__name__}.py\", \"r\") as file:\n",
    "#         exec(file.read())\n",
    "# __name__ = __name_bak__\n",
    "\n",
    "from cloudpickle import cloudpickle\n",
    "import youtube_watcher\n",
    "import vimeo_watcher\n",
    "import twitch_watcher\n",
    "import webdav\n",
    "cloudpickle.register_pickle_by_value(youtube_watcher)\n",
    "cloudpickle.register_pickle_by_value(vimeo_watcher)\n",
    "cloudpickle.register_pickle_by_value(twitch_watcher)\n",
    "cloudpickle.register_pickle_by_value(webdav)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "cf48376b8020cd44",
   "metadata": {},
   "source": [
    "These are the list of videos that we are testing. "
   ]
  },
  {
   "cell_type": "code",
   "id": "86647f3106ac223b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T05:04:49.649808Z",
     "start_time": "2024-12-12T05:04:49.647009Z"
    }
   },
   "source": [
    "youtube_ids = [\n",
    "    \"dQw4w9WgXcQ\",\n",
    "    \"r5JYHXtt_rw\",\n",
    "    \"pxEV1A5mTYM\",\n",
    "    \"Ct6BUPvE2sM\",\n",
    "    \"KjtYZpqvt50\"\n",
    "]\n",
    "\n",
    "youtube_videos = [f\"https://www.youtube.com/watch?v={v}\" for v in youtube_ids]\n",
    "\n",
    "vimeo_ids = [\n",
    "    375468729,\n",
    "    347119375,\n",
    "    297124334,\n",
    "    476306167,\n",
    "    515893651\n",
    "]\n",
    "\n",
    "vimeo_videos = [f\"https://vimeo.com/{v}?autoplay=1\" for v in vimeo_ids]\n",
    "\n",
    "twitch_ids = [\n",
    "    2322690366,\n",
    "    2298318732,\n",
    "    2316652767,\n",
    "    1867242354,\n",
    "    2320975412\n",
    "]\n",
    "\n",
    "twitch_videos = [f\"https://twitch.tv/video/{v}\" for v in twitch_ids]"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "afea1594f2156380",
   "metadata": {},
   "source": [
    "Load a list of proxies from https://free-proxy-list.net/ and create a Chrome argument for the proxy configuration."
   ]
  },
  {
   "cell_type": "code",
   "id": "ea57ccd81f730ab8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T05:04:49.802812Z",
     "start_time": "2024-12-12T05:04:49.655341Z"
    }
   },
   "source": [
    "proxies = [proxy for proxy in get_proxies() if proxy.https]\n",
    "\n",
    "proxy_arg = f\"\"\"--proxy-server={','.join([\n",
    "    f'https://{proxy.ip}:{proxy.port}'\n",
    "    for proxy in proxies\n",
    "] + ['direct://'])}\"\"\""
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "36ee46850609752",
   "metadata": {},
   "source": "Use `ngrok` to expose port `18080`. We'll use this as a https proxy."
  },
  {
   "cell_type": "code",
   "id": "9adaf4f83f77de5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T05:04:50.538875Z",
     "start_time": "2024-12-12T05:04:49.808988Z"
    }
   },
   "source": [
    "tcp_tunnel = ngrok.connect(\"18080\", \"tcp\")\n",
    "self_proxy = f\"https://{tcp_tunnel.public_url[6:]}\"\n",
    "self_proxy_arg = f\"--proxy-server={self_proxy},direct://\"\n",
    "tcp_tunnel\n",
    "# self_proxy"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<NgrokTunnel: \"tcp://6.tcp.us-cal-1.ngrok.io:10789\" -> \"localhost:18080\">"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "aaef23a7507d7c0",
   "metadata": {},
   "source": [
    "Create 10 pipelines, each doing these steps for YouTube, Vimeo, and Twitch:\n",
    "- watch video without proxies or background traffic\n",
    "- watch video using a proxy from https://free-proxy-list.net/ but no background traffic\n",
    "- watch video using the host machine as a proxy but no background traffic\n",
    "- watch video without proxies but with background traffic\n",
    "\n",
    "Each pipeline then uploads the result to http://snl-server-5.cs.ucsb.edu/cs190n/cs190n4/capture"
   ]
  },
  {
   "cell_type": "code",
   "id": "3fb17ba08afe12c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T05:04:50.553761Z",
     "start_time": "2024-12-12T05:04:50.548038Z"
    }
   },
   "source": [
    "from netunicorn.base import Task\n",
    "from collections.abc import Callable\n",
    "from typing import Type\n",
    "\n",
    "watch_tasks: dict[\n",
    "    str,\n",
    "    tuple[Type[WatchYouTubeVideo | WatchVimeoVideo | WatchTwitchStream], list[str]]\n",
    "] = {\n",
    "    'youtube': (WatchYouTubeVideo, youtube_videos),\n",
    "    'vimeo': (WatchVimeoVideo, vimeo_videos),\n",
    "    'twitch': (WatchTwitchStream, twitch_videos),\n",
    "}\n",
    "\n",
    "watch_types: dict[str, dict[str, any]] = {\n",
    "    '_': {\n",
    "        'get_processes': lambda name: [\n",
    "            [\"sudo\", \"tcpdump\", \"-i\", \"any\", \"-U\", \"-w\", f\"{name}.pcap\"]\n",
    "        ],\n",
    "        'requirements': [\n",
    "            \"sudo apt-get update\",\n",
    "            \"sudo apt-get install -y tcpdump\"\n",
    "        ]\n",
    "    },\n",
    "    '_proxy_': {\n",
    "        'get_processes': lambda name: [\n",
    "            [\"sudo\", \"tcpdump\", \"-i\", \"any\", \"-U\", \"-w\", f\"{name}.pcap\"]\n",
    "        ],\n",
    "        'webdriver_arguments': [proxy_arg],\n",
    "        'requirements': [\n",
    "            \"sudo apt-get update\",\n",
    "            \"sudo apt-get install -y tcpdump\"\n",
    "        ]\n",
    "    },\n",
    "    '_proxy1_': {\n",
    "        'get_processes': lambda name: [\n",
    "            [\"sudo\", \"tcpdump\", \"-i\", \"any\", \"-U\", \"-w\", f\"{name}.pcap\"]\n",
    "        ],\n",
    "        'webdriver_arguments': [self_proxy_arg],\n",
    "        'requirements': [\n",
    "            \"sudo apt-get update\",\n",
    "            \"sudo apt-get install -y tcpdump\"\n",
    "        ]\n",
    "    },\n",
    "    '_speedtest_': {\n",
    "        'get_processes': lambda name: [\n",
    "            [\"sudo\", \"tcpdump\", \"-i\", \"any\", \"-U\", \"-w\", f\"{name}.pcap\"],\n",
    "            [\"sh\", \"-c\", \"while true; do speedtest-cli --simple --secure; done\"]\n",
    "        ],\n",
    "        'requirements': [\n",
    "            \"sudo apt-get update\",\n",
    "            \"sudo apt-get install -y tcpdump\",\n",
    "            \"pip install speedtest-cli\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "def generate_pipeline(i: int, subdirectory: str) -> Pipeline:\n",
    "    pipeline = Pipeline(early_stopping=False)\n",
    "    \n",
    "    for watch_type, kwargs in watch_types.items():\n",
    "        for site, (TaskImpl, videos) in watch_tasks.items():\n",
    "            name = f\"{site}{watch_type}{i}\"\n",
    "\n",
    "            pipeline.then(TaskImpl(\n",
    "                video_url=videos,\n",
    "                duration=30,\n",
    "                name=f\"{site}{watch_type}{i}\",\n",
    "                **kwargs\n",
    "            ))\n",
    "    \n",
    "            pipeline.then(UploadToWebDav(\n",
    "                filepaths={f\"{name}.pcap\"},\n",
    "                endpoint=\"http://snl-server-5.cs.ucsb.edu/cs190n/cs190n4/capture\",\n",
    "                username=\"uploader\",\n",
    "                password=\"uploader\",\n",
    "                subdirectory=subdirectory,\n",
    "                name=f\"upload_{i}\"\n",
    "            ))\n",
    "    \n",
    "    return pipeline"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "d0ffd8b2134a186b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T05:04:50.562808Z",
     "start_time": "2024-12-12T05:04:50.560392Z"
    }
   },
   "source": [
    "working_node = \"aws-fargate-B\"\n",
    "experiment_label = \"team-4-experiment-12\""
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "d2e3ded0978edf07",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-12T05:04:50.577503Z"
    }
   },
   "source": [
    "# with open(\"./proxy_out.log\", \"w\") as stdout, open(\"./proxy_err.log\", \"w\") as stderr:\n",
    "#     proxy_env = os.environ.copy()\n",
    "#     proxy_env[\"PORT\"] = \"18080\"\n",
    "#     proxy_process = subprocess.Popen([\"node\", \"proxy.js\"], env=proxy_env, stdout=stdout, stderr=stderr)\n",
    "#     result = execute_pipeline(pipelines, working_node, experiment_label)\n",
    "#     proxy_process.terminate()\n",
    "\n",
    "subdirectory = str(uuid4())\n",
    "pipelines = [generate_pipeline(i, subdirectory) for i in range(10)]\n",
    "result = execute_pipeline(pipelines, working_node, experiment_label)\n",
    "result"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment executor_id: \n",
      "commands:\n",
      "apt install -y python3-pip wget xvfb procps\n",
      "pip3 install pytest-playwright\n",
      "playwright install-deps\n",
      "playwright install chromium\n",
      "sudo apt-get update\n",
      "sudo apt-get install -y tcpdump\n",
      "sudo apt-get install -y curl\n",
      "pip install speedtest-cli\n",
      "\n",
      "deployment executor_id: \n",
      "commands:\n",
      "apt install -y python3-pip wget xvfb procps\n",
      "pip3 install pytest-playwright\n",
      "playwright install-deps\n",
      "playwright install chromium\n",
      "sudo apt-get update\n",
      "sudo apt-get install -y tcpdump\n",
      "sudo apt-get install -y curl\n",
      "pip install speedtest-cli\n",
      "\n",
      "deployment executor_id: \n",
      "commands:\n",
      "apt install -y python3-pip wget xvfb procps\n",
      "pip3 install pytest-playwright\n",
      "playwright install-deps\n",
      "playwright install chromium\n",
      "sudo apt-get update\n",
      "sudo apt-get install -y tcpdump\n",
      "sudo apt-get install -y curl\n",
      "pip install speedtest-cli\n",
      "\n",
      "deployment executor_id: \n",
      "commands:\n",
      "apt install -y python3-pip wget xvfb procps\n",
      "pip3 install pytest-playwright\n",
      "playwright install-deps\n",
      "playwright install chromium\n",
      "sudo apt-get update\n",
      "sudo apt-get install -y tcpdump\n",
      "sudo apt-get install -y curl\n",
      "pip install speedtest-cli\n",
      "\n",
      "deployment executor_id: \n",
      "commands:\n",
      "apt install -y python3-pip wget xvfb procps\n",
      "pip3 install pytest-playwright\n",
      "playwright install-deps\n",
      "playwright install chromium\n",
      "sudo apt-get update\n",
      "sudo apt-get install -y tcpdump\n",
      "sudo apt-get install -y curl\n",
      "pip install speedtest-cli\n",
      "\n",
      "deployment executor_id: \n",
      "commands:\n",
      "apt install -y python3-pip wget xvfb procps\n",
      "pip3 install pytest-playwright\n",
      "playwright install-deps\n",
      "playwright install chromium\n",
      "sudo apt-get update\n",
      "sudo apt-get install -y tcpdump\n",
      "sudo apt-get install -y curl\n",
      "pip install speedtest-cli\n",
      "\n",
      "deployment executor_id: \n",
      "commands:\n",
      "apt install -y python3-pip wget xvfb procps\n",
      "pip3 install pytest-playwright\n",
      "playwright install-deps\n",
      "playwright install chromium\n",
      "sudo apt-get update\n",
      "sudo apt-get install -y tcpdump\n",
      "sudo apt-get install -y curl\n",
      "pip install speedtest-cli\n",
      "\n",
      "deployment executor_id: \n",
      "commands:\n",
      "apt install -y python3-pip wget xvfb procps\n",
      "pip3 install pytest-playwright\n",
      "playwright install-deps\n",
      "playwright install chromium\n",
      "sudo apt-get update\n",
      "sudo apt-get install -y tcpdump\n",
      "sudo apt-get install -y curl\n",
      "pip install speedtest-cli\n",
      "\n",
      "deployment executor_id: \n",
      "commands:\n",
      "apt install -y python3-pip wget xvfb procps\n",
      "pip3 install pytest-playwright\n",
      "playwright install-deps\n",
      "playwright install chromium\n",
      "sudo apt-get update\n",
      "sudo apt-get install -y tcpdump\n",
      "sudo apt-get install -y curl\n",
      "pip install speedtest-cli\n",
      "\n",
      "deployment executor_id: \n",
      "commands:\n",
      "apt install -y python3-pip wget xvfb procps\n",
      "pip3 install pytest-playwright\n",
      "playwright install-deps\n",
      "playwright install chromium\n",
      "sudo apt-get update\n",
      "sudo apt-get install -y tcpdump\n",
      "sudo apt-get install -y curl\n",
      "pip install speedtest-cli\n",
      "\n",
      "ExperimentStatus.PREPARING\n",
      "ExperimentStatus.PREPARING\n",
      "ExperimentStatus.PREPARING\n",
      "ExperimentStatus.PREPARING\n",
      "ExperimentStatus.PREPARING\n",
      "ExperimentStatus.PREPARING\n",
      "ExperimentStatus.PREPARING\n",
      "ExperimentStatus.PREPARING\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "158227dd2aa6a8c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T05:04:16.671202Z",
     "start_time": "2024-12-12T04:58:51.286488Z"
    }
   },
   "source": [
    "directory = f\"/mnt/md0/cs190n/cs190n4/capture/{subdirectory}\"\n",
    "    \n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith(\".pcap\"): \n",
    "        print(os.path.join(directory, file))\n",
    "        !docker run -v {directory}:/tmp/input -v ./data/unprocessed:/tmp/output mielverkerken/cicflowmeter /tmp/input/{file} /tmp/output > /dev/null 2>&1"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/md0/cs190n/cs190n4/capture/5dcb8695-45ff-4c44-a3c8-70efe1ae8b69'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m directory \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/mnt/md0/cs190n/cs190n4/capture/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msubdirectory\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlistdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdirectory\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m file\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.pcap\u001B[39m\u001B[38;5;124m\"\u001B[39m): \n\u001B[1;32m      5\u001B[0m         \u001B[38;5;28mprint\u001B[39m(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(directory, file))\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/mnt/md0/cs190n/cs190n4/capture/5dcb8695-45ff-4c44-a3c8-70efe1ae8b69'"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "24c3ea9c914a2b8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T05:04:16.671303Z",
     "start_time": "2024-12-11T23:58:42.818073Z"
    }
   },
   "source": [
    "ips = []\n",
    "\n",
    "# Youtube\n",
    "ips += \"\"\"\t\n",
    "2404:6800:4003:c04::5d\n",
    "2404:6800:4004:809::200e\n",
    "2404:6800:4006:809::200e\n",
    "2607:f8b0:4004:814::200e\n",
    "2607:f8b0:4005:809::200e\n",
    "2607:f8b0:400a:809::200e\n",
    "2800:3f0:4001:80a::200e\n",
    "2a00:1450:4009:81d::200e\n",
    "2a00:1450:400b:804::200e\n",
    "74.125.90.110\n",
    "142.250.179.238\n",
    "172.217.3.206\n",
    "172.217.6.46\n",
    "172.217.26.14\n",
    "172.217.30.78\n",
    "172.217.164.142\n",
    "172.217.194.91\n",
    "172.217.194.93\n",
    "172.217.194.136\n",
    "172.217.194.190\n",
    "216.58.203.110\n",
    "\"\"\".strip().split(\"\\n\")\n",
    "\n",
    "# Vimeo\n",
    "ips += \"\"\"\n",
    "151.101.0.217\n",
    "151.101.64.217\n",
    "151.101.128.217\n",
    "151.101.192.217\n",
    "\"\"\".strip().split(\"\\n\")\n",
    "\n",
    "# Twitch\n",
    "ips += \"\"\"\n",
    "151.101.2.167\n",
    "151.101.66.167\n",
    "151.101.130.167\n",
    "151.101.194.167\n",
    "\"\"\".strip().split(\"\\n\")\n",
    "\n",
    "# proxies\n",
    "ips += [proxy.ip for proxy in proxies]\n",
    "\n",
    "ips.append(re.search(r\"(?<=https:\\/\\/).*?(?=:)\", self_proxy).group())"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "2591f2686ea521cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T05:04:16.671374Z",
     "start_time": "2024-12-11T23:58:42.827348Z"
    }
   },
   "source": [
    "twitch_captures = []\n",
    "twitch_capture_proxies = []\n",
    "twitch_capture_proxies1 = []\n",
    "twitch_capture_speedtests = []\n",
    "vimeo_captures = []\n",
    "vimeo_capture_proxies = []\n",
    "vimeo_capture_proxies1 = []\n",
    "vimeo_capture_speedtests = []\n",
    "youtube_captures = []\n",
    "youtube_capture_proxies = []\n",
    "youtube_capture_proxies1 = []\n",
    "youtube_capture_speedtests = []\n",
    "\n",
    "twitch_ips = []\n",
    "vimeo_ips = []\n",
    "youtube_ips = []\n",
    "\n",
    "for glob, captures, ips in [\n",
    "    (\"twitch_*.pcap_Flow.csv\", twitch_captures, twitch_ips),\n",
    "    (\"vimeo_*.pcap_Flow.csv\", vimeo_captures, vimeo_ips),\n",
    "    (\"youtube_*.pcap_Flow.csv\", youtube_captures, youtube_ips),\n",
    "]:\n",
    "    for path in Path(\"data/unprocessed\").glob(glob):\n",
    "        df = pd.read_csv(path, sep=\",\")\n",
    "        df = df[((df['Total Fwd Packet'] > 30) | (df['Total Bwd packets'] > 30)) & (df[\"Protocol\"] == 6)]\n",
    "        df = df.drop(['Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol', 'Timestamp'], axis=1)\n",
    "        df[\"Label\"] = glob.split(\"_\", 1)[0]\n",
    "        ips.extend(df[\"Dst IP\"].unique())\n",
    "        captures.append(df)\n",
    "\n",
    "for glob, captures, ips in [\n",
    "    (\"twitch_proxy_*.pcap_Flow.csv\", twitch_capture_proxies, twitch_ips),\n",
    "    (\"twitch_proxy1_*.pcap_Flow.csv\", twitch_capture_proxies1, twitch_ips),\n",
    "    (\"vimeo_proxy_*.pcap_Flow.csv\", vimeo_capture_proxies, vimeo_ips),\n",
    "    (\"vimeo_proxy1_*.pcap_Flow.csv\", vimeo_capture_proxies1, vimeo_ips),\n",
    "    (\"youtube_proxy_*.pcap_Flow.csv\", youtube_capture_proxies, youtube_ips),\n",
    "    (\"youtube_proxy1_*.pcap_Flow.csv\", youtube_capture_proxies1, youtube_ips)\n",
    "]:\n",
    "    for path in Path(\"data/unprocessed\").glob(glob):\n",
    "        df = pd.read_csv(path, sep=\",\")\n",
    "        df = df[((df['Total Fwd Packet'] > 30) | (df['Total Bwd packets'] > 30)) & (df[\"Protocol\"] == 6)]\n",
    "        ips.extend(df[\"Dst IP\"].unique())\n",
    "        df = df.drop(['Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol', 'Timestamp'], axis=1)\n",
    "        df[\"Label\"] = glob.split(\"_\", 1)[0]\n",
    "\n",
    "for glob, captures, ips in [\n",
    "    (\"twitch_speedtest_*.pcap_Flow.csv\", twitch_capture_speedtests, twitch_ips),\n",
    "    (\"vimeo_speedtest_*.pcap_Flow.csv\", vimeo_capture_speedtests, vimeo_ips),\n",
    "    (\"youtube_speedtest_*.pcap_Flow.csv\", youtube_capture_speedtests, youtube_ips),\n",
    "]:\n",
    "    for path in Path(\"data/unprocessed\").glob(glob):\n",
    "        df = pd.read_csv(path, sep=\",\")\n",
    "        df = df[(df[\"Dst IP\"].isin(ips)) & (df[\"Protocol\"] == 6)]\n",
    "        df = df.drop(['Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol', 'Timestamp'], axis=1)\n",
    "        df[\"Label\"] = glob.split(\"_\", 1)[0]\n",
    "        captures.append(df)"
   ],
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Dst IP'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/PycharmProjects/ucsb-cs190n-f24-group-4/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3629\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3628\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3629\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3630\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/PycharmProjects/ucsb-cs190n-f24-group-4/.venv/lib/python3.10/site-packages/pandas/_libs/index.pyx:136\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/PycharmProjects/ucsb-cs190n-f24-group-4/.venv/lib/python3.10/site-packages/pandas/_libs/index.pyx:163\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'Dst IP'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 28\u001B[0m\n\u001B[1;32m     26\u001B[0m         df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mdrop([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSrc IP\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSrc Port\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDst IP\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDst Port\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mProtocol\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTimestamp\u001B[39m\u001B[38;5;124m'\u001B[39m], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     27\u001B[0m         df[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLabel\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m glob\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m1\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m---> 28\u001B[0m         ips\u001B[38;5;241m.\u001B[39mextend(\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDst IP\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39munique())\n\u001B[1;32m     29\u001B[0m         captures\u001B[38;5;241m.\u001B[39mappend(df)\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m glob, captures, ips \u001B[38;5;129;01min\u001B[39;00m [\n\u001B[1;32m     32\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtwitch_proxy_*.pcap_Flow.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m, twitch_capture_proxies, twitch_ips),\n\u001B[1;32m     33\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtwitch_proxy1_*.pcap_Flow.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m, twitch_capture_proxies1, twitch_ips),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     37\u001B[0m     (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myoutube_proxy1_*.pcap_Flow.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m, youtube_capture_proxies1, youtube_ips)\n\u001B[1;32m     38\u001B[0m ]:\n",
      "File \u001B[0;32m~/PycharmProjects/ucsb-cs190n-f24-group-4/.venv/lib/python3.10/site-packages/pandas/core/frame.py:3505\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3503\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3504\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3505\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3507\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/PycharmProjects/ucsb-cs190n-f24-group-4/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3631\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3629\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3630\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3631\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3632\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3633\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3634\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3635\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3636\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'Dst IP'"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6aa00bf1f424bc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T05:04:16.671449Z",
     "start_time": "2024-12-11T00:39:50.958547Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.concat(twitch_captures).to_csv(\"data/twitch_captures.csv\")\n",
    "pd.concat(twitch_capture_proxies).to_csv(\"data/twitch_capture_proxies.csv\")\n",
    "pd.concat(twitch_capture_proxies1).to_csv(\"data/twitch_capture_proxies1.csv\")\n",
    "pd.concat(twitch_capture_speedtests).to_csv(\"data/twitch_capture_speedtests.csv\")\n",
    "pd.concat(vimeo_captures).to_csv(\"data/vimeo_captures.csv\")\n",
    "pd.concat(vimeo_capture_proxies).to_csv(\"data/vimeo_capture_proxies.csv\")\n",
    "pd.concat(vimeo_capture_proxies1).to_csv(\"data/vimeo_capture_proxies1.csv\")\n",
    "pd.concat(vimeo_capture_speedtests).to_csv(\"data/vimeo_capture_speedtests.csv\")\n",
    "pd.concat(youtube_captures).to_csv(\"data/youtube_captures.csv\")\n",
    "pd.concat(youtube_capture_proxies).to_csv(\"data/youtube_capture_proxies.csv\")\n",
    "pd.concat(youtube_capture_proxies1).to_csv(\"data/youtube_capture_proxies1.csv\")\n",
    "pd.concat(youtube_capture_speedtests).to_csv(\"data/youtube_capture_speedtests.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "711ce9f0f700fb1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T05:04:16.671503Z",
     "start_time": "2024-12-11T04:08:54.058927Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<youtube_capture_0.pcap: TCP:3334 UDP:80068 ICMP:0 Other:29>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from scapy.all import *\n",
    "# \n",
    "# # rdpcap(\"/mnt/md0/cs190n/cs190n4/capture/f96448c3-e829-4752-bd3e-752097078e98/tmp/youtube_capture_0.pcap\")\n",
    "# # rdpcap(\"/mnt/md0/cs190n/cs190n4/capture/edae735b-ace9-45ef-b0ff-0b4ebade43b2/tmp/twitch_capture.pcap\")\n",
    "# foo = rdpcap(\"/mnt/md0/cs190n/cs190n4/capture/ac772645-dffb-4a44-957e-0b67ee4be6ab/tmp/youtube_capture_0.pcap\")\n",
    "# foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a15052b8b5f66c09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T05:04:16.671627Z",
     "start_time": "2024-12-11T04:12:22.129042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CookedLinuxV2  proto=IPv4 reserved=0 ifindex=4 lladdrtype=0x1 pkttype=sent-by-us lladdrlen=6 src=b'\\x02\\xb1\\xdc\\x80T\\x8b' |<IP  version=4 ihl=5 tos=0x0 len=58 id=63199 flags=DF frag=0 ttl=127 proto=udp chksum=0xea18 src=10.113.5.215 dst=10.113.0.2 |<UDP  sport=57380 dport=domain len=38 chksum=0x1af2 |<DNS  id=7563 qr=0 opcode=QUERY aa=0 tc=0 rd=1 ra=0 z=0 ad=0 cd=0 rcode=ok qdcount=1 ancount=0 nscount=0 arcount=0 qd=[<DNSQR  qname=b'plausible.io.' qtype=A unicastresponse=0 qclass=IN |>] |>>>>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# foo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6c67392035d22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-12T05:04:16.671703Z",
     "start_time": "2024-12-11T04:52:45.205199Z"
    }
   },
   "outputs": [],
   "source": [
    "# result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
